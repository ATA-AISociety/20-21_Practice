import numpy as np
import matplotlib.pyplot as plt
import os
import cv2
import random
import pickle
import tensorflow as tf
from tensorflow import keras

IMG_SIZE = 64 #Resize Images
'''

training_data = []
def create_training_data():

    directory = r"C:/Users/Jorda_000/Desktop/Dataset"
    categories = ["Anime", "Humans"]
    for cat in categories:
        path = os.path.join(directory, cat)# Path To folder containing images
        class_num = categories.index(cat)
        for img in os.listdir(path):
            try:
                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE) # Grabs images and converts them to greyscale
                new_images = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # new images will be a 64 by 64 image
                training_data.append([new_images, class_num])
            except Exception as e:
                print("passing at " + str(class_num))
                pass


create_training_data()
print('Done with dataset')
print(len(training_data))

#random.shuffle(training_data)

#for sample in training_images:
#    print(sample[1])

training_images = []
training_labels = []

for features, labels in training_data:
    training_images.append(features)
    training_labels.append(labels)


#Reshaping is important for the Flatten() command. Flatten only accepts 3 arguments
training_images = np.array(training_images).reshape(-1, IMG_SIZE, IMG_SIZE) #Note -1 is a catchall and 1 is only because the images are greuscale
'''
###############################################################
'''
#To save our data so it doesn't always have to be loaded
pickle_out = open("tImage_unsorted.pickle", "wb")
pickle.dump(training_images, pickle_out)
pickle_out.close()

pickle_out = open("tLabel_unsorted.pickle", "wb")
pickle.dump(training_labels, pickle_out)
pickle_out.close()
'''
##############################################################

pickle_in= open("tImage_unsorted.pickle", "rb")
tImage_unsorted = pickle.load(pickle_in)

pickle_in= open("tLabel_unsorted.pickle", "rb")
tLabel_unsorted = pickle.load(pickle_in)

#############################################################
x = 0
y = 0
z = 0
animeImg = []
humanFaceImg = []


for image in tImage_unsorted:
    if(tLabel_unsorted[x] == 0):
        animeImg.append(image)
        #print("Anime " + str(x) + " , " + str(y))
        y = y + 1
    else:
        humanFaceImg.append(image)
        #print("Human " + str(x) + " , " + str(z))
        z = z + 1
    x = x + 1
###########################################################

edittedAnime = []
edittedHumans = []
allImagesEditted = []
edittedImageLabels = []

for i in range(0, len(animeImg)):
    newImg = cv2.adaptiveThreshold(animeImg[i], 127, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY, 17, 0)
    edittedAnime.append(newImg)
    if(i < 7220):
        edittedImageLabels.append(tLabel_unsorted[i])
        allImagesEditted.append(newImg)

for i in range(0, len(humanFaceImg)):
    newImg = cv2.adaptiveThreshold(humanFaceImg[i], 127, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 17, 0)
    edittedHumans.append(newImg)
    allImagesEditted.append(newImg)
    edittedImageLabels.append(tLabel_unsorted[i])
#for img in allImagesEditted:
    #cv2.imshow("Editted", img)
    #cv2.waitKey(0)


#allImagesEditted = np.array(allImagesEditted).reshape(-1, IMG_SIZE, IMG_SIZE)

pairedData = [[0]*2] * len(allImagesEditted)

for i in range(0, len(allImagesEditted)):
    for e in range(0,2):
        if(e == 0):
            pairedData[i][e] = allImagesEditted[i]
        else:
            #print(edittedImageLabels[i])
            pairedData[i][e] = edittedImageLabels[i]
            #print(pairedData[i][e])

#print(pairedData)

random.shuffle(pairedData)

ranEdittedImg = []
ranEdittedLabel = []

for features, labels in pairedData:
    ranEdittedImg.append(features)
    ranEdittedLabel.append(labels)

ranEdittedImg = np.array(ranEdittedImg).reshape(-1, IMG_SIZE, IMG_SIZE)

class_names = ["Anime Face, Human Face"]
model = keras.Sequential([keras.layers.Flatten(input_shape=(64,64)), keras.layers.Dense(128, activation=tf.nn.relu), keras.layers.Dense(10, activation=tf.nn.softmax)])
model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])
model.fit(ranEdittedImg, ranEdittedLabel, epochs=5)
